{
 "cells": [
  {
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T12:21:52.018012Z",
     "start_time": "2021-01-18T12:21:49.980371Z"
    }
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T12:21:52.028895Z",
     "start_time": "2021-01-18T12:21:52.018921Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_variable(df):  # 파생변수 생성\n",
    "    \n",
    "    df['sum_energy'] = df['DHI'] + df['DNI']\n",
    "\n",
    "    df['theta'] = 0\n",
    "    condition_list = [\n",
    "        (df['Hour'] == 6) | (df['Hour'] == 19),\n",
    "        (df['Hour'] == 7) | (df['Hour'] == 18),\n",
    "        (df['Hour'] == 8) | (df['Hour'] == 17),\n",
    "        (df['Hour'] == 9) | (df['Hour'] == 16),\n",
    "        (df['Hour'] == 10) | (df['Hour'] == 15),\n",
    "        (df['Hour'] == 11) | (df['Hour'] == 14),\n",
    "        (df['Hour'] == 12) | (df['Hour'] == 13)\n",
    "    ]\n",
    "\n",
    "    choice_list = [0, 10, 20, 30, 40, 50, 60]\n",
    "\n",
    "    df['theta'] = np.select(condition_list, choice_list)\n",
    "    # GHI\n",
    "    df['GHI'] = df['DNI'] * np.cos(df['theta']) + df['DHI']\n",
    "\n",
    "    # 변수 추가\n",
    "    condition_list = [\n",
    "        ((df['Hour'] >= 0) & (df['Hour'] <= 7)) | ((df['Hour'] >= 18) & (df['Hour'] <= 23)),\n",
    "        ((df['Hour'] > 7) & (df['Hour'] < 10)) | ((df['Hour'] >= 15) & (df['Hour'] < 18)),\n",
    "        (df['Hour'] >=10) & (df['Hour'] < 15),\n",
    "    ]\n",
    "\n",
    "    choice_list = [0, 2, 1]\n",
    "\n",
    "    df['time'] = np.select(condition_list, choice_list)\n",
    "    df['target0'] = df['TARGET']\n",
    "\n",
    "\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T12:21:52.043881Z",
     "start_time": "2021-01-18T12:21:52.034881Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "ETA = 0.005\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ys/repo/solar_prediction/data/train/train.csv')\n",
    "df = add_variable(df)\n",
    "\n",
    "X = df.drop('TARGET', axis = 1)\n",
    "y = df['TARGET']\n",
    "\n",
    "X_train = X[:47280]\n",
    "y_train = y[:47280]\n",
    "\n",
    "X_test = X[47280:]\n",
    "y_test = y[47280:]\n",
    "\n",
    "#X_train, X_test, y_train, y_test =train_test_split(X, y, test_size = 0.1, shuffle = False)\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildDataset(Dataset): \n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = torch.tensor(X.values.astype(np.float))\n",
    "        self.y = torch.tensor(y.values.astype(np.float))\n",
    "        self.X = self.X.reshape(13,-1)\n",
    "        self.y = self.y.reshape(1,-1)\n",
    "        self.seq_len= seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[1] // self.seq_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index += 48\n",
    "        return (self.X[:,index:index+self.seq_len], self.y[:,index:index+self.seq_len])"
   ]
  },
  {
   "source": [
    "### Day 2 Prediction Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 13, out_channels = 12, kernel_size = 1),\n",
    "            nn.BatchNorm1d(12),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(in_channels = 12, out_channels = 10, kernel_size = 4),\n",
    "            nn.BatchNorm1d(10),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(in_channels = 10, out_channels = 8, kernel_size = 8),\n",
    "            nn.BatchNorm1d(8),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 8, out_channels = 6, kernel_size = 4),\n",
    "            nn.BatchNorm1d(6),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(in_channels = 6, out_channels = 4, kernel_size = 1),\n",
    "            nn.BatchNorm1d(4),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(in_channels = 4, out_channels = 1, kernel_size = 1),\n",
    "            #nn.BatchNorm1d(1),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(227, 144),\n",
    "            nn.Linear(144, 96),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x).float()\n",
    "        out = self.layer1(x)\n",
    "        #print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        #print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = BuildDataset(X_train, y_train, seq_len = 240+96)\n",
    "trn_loader = data_utils.DataLoader(trn_dataset, shuffle = False)\n",
    "tst_dataset = BuildDataset(X_test, y_test, seq_len = 240+96)\n",
    "tst_loader = data_utils.DataLoader(tst_dataset, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T12:45:04.172826Z",
     "start_time": "2021-01-18T12:45:04.167844Z"
    }
   },
   "outputs": [],
   "source": [
    "def quantile_loss(pred, gt, quantile):\n",
    "    qs = quantile\n",
    "    sum_loss = 0\n",
    "    loss = gt - pred\n",
    "    loss = torch.max(qs*loss, (qs-1)*loss)\n",
    "    sum_loss = torch.mean(loss)\n",
    "    return sum_loss\n",
    "\n",
    "model = CNN2().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = ETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T12:45:04.371306Z",
     "start_time": "2021-01-18T12:45:04.367308Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, trn_loader, optimizer, epoch, quantile):\n",
    "    model.train()\n",
    "\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trn_loader):\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        data = data[:,:,:240]\n",
    "        target = target[:,:,240:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = quantile_loss(output, target, quantile)\n",
    "\n",
    "        running_train_loss += loss\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {} | Train Loss:{:.3f}'.format(epoch, running_train_loss / len(trn_loader)))\n",
    "\n",
    "    \"\"\"\n",
    "    # for validation\n",
    "    running_dev_loss = 0.0\n",
    "    for i, data in enumerate(dev_loader):\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        output = model(data)\n",
    "        target = target.view(1,1,48)\n",
    "\n",
    "        loss = quantile_loss(output, target)\n",
    "\n",
    "        running_dev_loss += loss\n",
    "\n",
    "    print('Epoch: {} | Valid Loss:{:.3f}'.format(epoch, running_dev_loss / len(dev_loader)))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T12:45:04.532877Z",
     "start_time": "2021-01-18T12:45:04.526890Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, tst_loader, quantile): \n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "     \n",
    "    with torch.no_grad(): \n",
    "        for i, data in enumerate(tst_loader): \n",
    "            data, target = data[0].to(device), data[1].to(device) \n",
    "\n",
    "            data = data[:,:,:240]\n",
    "            target = target[:,:,240:]   \n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "        \n",
    "            loss = quantile_loss(output, target, quantile)\n",
    "            \n",
    "            running_test_loss += loss\n",
    "\n",
    "        print('Test Loss: {:.4f}'.format(running_test_loss / len(tst_loader)))\n",
    "        print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T12:52:18.948531Z",
     "start_time": "2021-01-18T12:45:04.711495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "quantile : 0.1\n",
      "Epoch: 10 | Train Loss:1.906\n",
      "Epoch: 20 | Train Loss:1.902\n",
      "Epoch: 30 | Train Loss:1.900\n",
      "Epoch: 40 | Train Loss:1.899\n",
      "Epoch: 50 | Train Loss:1.899\n",
      "Test Loss: 2.4241\n",
      "==============================\n",
      "quantile : 0.2\n",
      "Epoch: 10 | Train Loss:3.798\n",
      "Epoch: 20 | Train Loss:3.798\n",
      "Epoch: 30 | Train Loss:3.797\n",
      "Epoch: 40 | Train Loss:3.797\n",
      "Epoch: 50 | Train Loss:3.797\n",
      "Test Loss: 4.8462\n",
      "==============================\n",
      "quantile : 0.3\n",
      "Epoch: 10 | Train Loss:5.696\n",
      "Test Loss: 7.2690\n",
      "==============================\n",
      "quantile : 0.4\n",
      "Epoch: 10 | Train Loss:7.594\n",
      "Test Loss: 9.6917\n",
      "==============================\n",
      "quantile : 0.5\n",
      "Epoch: 10 | Train Loss:9.492\n",
      "Test Loss: 12.1144\n",
      "==============================\n",
      "quantile : 0.6\n",
      "Epoch: 10 | Train Loss:11.391\n",
      "Test Loss: 14.5370\n",
      "==============================\n",
      "quantile : 0.7\n",
      "Epoch: 10 | Train Loss:13.280\n",
      "Test Loss: 16.9471\n",
      "==============================\n",
      "quantile : 0.8\n",
      "Epoch: 10 | Train Loss:14.534\n",
      "Test Loss: 18.6549\n",
      "==============================\n",
      "quantile : 0.9\n",
      "Epoch: 10 | Train Loss:6.800\n",
      "Test Loss: 10.9564\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]):\n",
    "    PATH = './model_day2/model_{}'.format(i+1)\n",
    "    print('quantile : {}'.format(q))\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        if (q >= 0.3) & (epoch == 11):\n",
    "            break\n",
    "        train(model, trn_loader, optimizer, epoch, quantile = q)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "    test_loss = evaluate(model, tst_loader, quantile = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/ys/repo/solar_prediction/data/test/0.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/1.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/2.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/3.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/4.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/5.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/6.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/7.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/8.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/9.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/10.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/11.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/12.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/13.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/14.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/15.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/16.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/17.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/18.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/19.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/20.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/21.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/22.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/23.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/24.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/25.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/26.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/27.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/28.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/29.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/30.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/31.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/32.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/33.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/34.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/35.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/36.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/37.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/38.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/39.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/40.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/41.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/42.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/43.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/44.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/45.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/46.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/47.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/48.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/49.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/50.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/51.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/52.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/53.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/54.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/55.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/56.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/57.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/58.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/59.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/60.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/61.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/62.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/63.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/64.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/65.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/66.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/67.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/68.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/69.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/70.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/71.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/72.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/73.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/74.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/75.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/76.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/77.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/78.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/79.csv\n",
      "336\n",
      "/home/ys/repo/solar_prediction/data/test/80.csv\n",
      "336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_result = pd.DataFrame([])\n",
    "total_result = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,81):\n",
    "    model2 = CNN2()\n",
    "\n",
    "    path = '/home/ys/repo/solar_prediction/data/test/' + str(i) +'.csv'\n",
    "    print(path)\n",
    "    df = pd.read_csv(path)\n",
    "    df = add_variable(df)\n",
    "    \n",
    "    df2 = df[(df['Day'] != 0) | (df['Day'] != 1)]\n",
    "    X2 = df2.drop('TARGET', axis = 1)\n",
    "    print(len(X2))\n",
    "    y2 = df2['TARGET']\n",
    "    tst_dataset2 = BuildDataset(X2, y2, seq_len = 240+96)\n",
    "    tst_loader2 = data_utils.DataLoader(tst_dataset2, shuffle = False)\n",
    "    #print(len(tst_loader2))\n",
    "\n",
    "    result2 = pd.DataFrame([])\n",
    "    result2['id'] = 0\n",
    "    result2['hour'] = 0\n",
    "\n",
    "    X2['Minute'] = X2['Minute'].astype('str')\n",
    "    X2['Minute'] = X2['Minute'].replace('0','00')\n",
    "    X2['Hour'] = X2['Hour'].astype('int')\n",
    "\n",
    "    for j,k in enumerate([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "        quantile = k\n",
    "        loss = 0\n",
    "        \n",
    "\n",
    "        PATH2 = '/home/ys/repo/solar_prediction/02_model/YS/model_day2/model_{}'.format(j+1)\n",
    "        model2.load_state_dict(torch.load(PATH2))\n",
    "\n",
    "        for _, data in enumerate(tst_loader2):\n",
    "            data = data[0]\n",
    "            data = data[:,:,:-48]\n",
    "            output = model2(data)\n",
    "            output = output.reshape(96,)\n",
    "            output = output.detach().numpy()\n",
    "\n",
    "            result2['q_{}'.format(k)] = output\n",
    "\n",
    "            for h in range(96):\n",
    "                result2['id'].loc[h] = '{}.csv_Day{}_{}h{}m'.format(i, X2['Day'].iloc[h]+7, X2['Hour'].iloc[h], X2['Minute'].iloc[h])\n",
    "                result2['hour'].loc[h] = X2['Hour'].iloc[h]\n",
    "                \n",
    "                if (result2['hour'].loc[h] < 7) | (result2['hour'].loc[h] > 19):\n",
    "                    result2['q_{}'.format(k)].iloc[h] = 0\n",
    "                if result2['q_{}'.format(k)].loc[h] < 0:\n",
    "                    result2['q_{}'.format(k)].iloc[h] = 0\n",
    "            \n",
    "                if k < 0.8:\n",
    "                    result2['q_{}'.format(k)].loc[h] = result2['q_{}'.format(k)].iloc[h] * 1000\n",
    "                if k >= 0.8:\n",
    "                    result2['q_{}'.format(k)].loc[h] = result2['q_{}'.format(k)].iloc[h] * 1000\n",
    "\n",
    "                \n",
    "        total_result = pd.concat([result2, total_result])\n",
    "\n",
    "    final_result = pd.concat([final_result, result2])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = final_result.drop(['hour'], axis =1)\n",
    "final_result.to_csv('submission_conv6.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a79844178d930ccad4ea29a50db83a54de481f46f913f5a9f67826328eb8a990"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}