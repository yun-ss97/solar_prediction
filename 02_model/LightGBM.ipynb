{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tools\n",
    "import joblib\n",
    "from typing import Tuple\n",
    "\n",
    "# preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# model\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼설명\n",
    "* Hour - 시간\n",
    "* Minute - 분\n",
    "* DHI - 수평면 산란일사량(Diffuse Horizontal Irradiance (W/m2)) : 태양광선이 대기를 통과하는 동안에 공기분자, 구름, 연무(aerosol) 입자 등으로 인하여 산란되어 도달되는 햇볕\n",
    "* DNI - 직달일사량(Direct Normal Irradiance (W/m2)) : 태양으로부터 지표에 직접 도달하는 햇볕\n",
    "* WS - 풍속(Wind Speed (m/s))\n",
    "* RH - 상대습도(Relative Humidity (%))\n",
    "* T - 기온(Temperature (Degree C))\n",
    "* Target - 태양광 발전량 (kW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.08</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.06</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>71.78</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>71.75</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>75.20</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52555</th>\n",
       "      <td>1094</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>70.70</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52556</th>\n",
       "      <td>1094</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>66.79</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52557</th>\n",
       "      <td>1094</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>66.78</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52558</th>\n",
       "      <td>1094</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>67.72</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52559</th>\n",
       "      <td>1094</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>67.70</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52560 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day  Hour  Minute  DHI  DNI   WS     RH   T  TARGET\n",
       "0         0     0       0    0    0  1.5  69.08 -12     0.0\n",
       "1         0     0      30    0    0  1.5  69.06 -12     0.0\n",
       "2         0     1       0    0    0  1.6  71.78 -12     0.0\n",
       "3         0     1      30    0    0  1.6  71.75 -12     0.0\n",
       "4         0     2       0    0    0  1.6  75.20 -12     0.0\n",
       "...     ...   ...     ...  ...  ...  ...    ...  ..     ...\n",
       "52555  1094    21      30    0    0  2.4  70.70  -4     0.0\n",
       "52556  1094    22       0    0    0  2.4  66.79  -4     0.0\n",
       "52557  1094    22      30    0    0  2.2  66.78  -4     0.0\n",
       "52558  1094    23       0    0    0  2.1  67.72  -4     0.0\n",
       "52559  1094    23      30    0    0  2.1  67.70  -4     0.0\n",
       "\n",
       "[52560 rows x 9 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../00_data/train/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "      <td>52560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>547.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>64.344121</td>\n",
       "      <td>234.792371</td>\n",
       "      <td>2.456033</td>\n",
       "      <td>56.793102</td>\n",
       "      <td>9.279928</td>\n",
       "      <td>17.790630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>316.102148</td>\n",
       "      <td>6.922252</td>\n",
       "      <td>15.000143</td>\n",
       "      <td>103.897125</td>\n",
       "      <td>349.684583</td>\n",
       "      <td>1.426874</td>\n",
       "      <td>22.052875</td>\n",
       "      <td>10.179741</td>\n",
       "      <td>25.759955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.590000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>273.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>39.697500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>547.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>57.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>821.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>72.770000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>32.089890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1094.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>99.913939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Day          Hour        Minute           DHI           DNI  \\\n",
       "count  52560.000000  52560.000000  52560.000000  52560.000000  52560.000000   \n",
       "mean     547.000000     11.500000     15.000000     64.344121    234.792371   \n",
       "std      316.102148      6.922252     15.000143    103.897125    349.684583   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      273.000000      5.750000      0.000000      0.000000      0.000000   \n",
       "50%      547.000000     11.500000     15.000000      0.000000      0.000000   \n",
       "75%      821.000000     17.250000     30.000000     87.000000    469.000000   \n",
       "max     1094.000000     23.000000     30.000000    528.000000   1059.000000   \n",
       "\n",
       "                 WS            RH             T        TARGET  \n",
       "count  52560.000000  52560.000000  52560.000000  52560.000000  \n",
       "mean       2.456033     56.793102      9.279928     17.790630  \n",
       "std        1.426874     22.052875     10.179741     25.759955  \n",
       "min        0.000000      7.590000    -19.000000      0.000000  \n",
       "25%        1.400000     39.697500      1.000000      0.000000  \n",
       "50%        2.200000     57.600000      9.000000      0.000000  \n",
       "75%        3.200000     72.770000     17.000000     32.089890  \n",
       "max       12.000000    100.000000     35.000000     99.913939  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df.TARGET, \n",
    "            notch=1, # if 'True' then notched box plot\n",
    "            sym='rs', # symbol: red square\n",
    "            vert=0 # vertical : if 'False' then horizontal box plot\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 32.0898895075, 99.91393869]\n"
     ]
    }
   ],
   "source": [
    "quan_val = []\n",
    "for i in range(4):\n",
    "    quan_val.append(df.TARGET.quantile(0.25*(i+1)))\n",
    "print(quan_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2935419ac70>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAulklEQVR4nO3de3Bc53nn+e+DbnQD3biSBC8iKYqyaUmUY13CkeR4xokvsiklMTO1u7XSxqtElR2OZqRsPJudrJxsbSVbqZnZqdlk7JRGisZWYsWONR7LThgvy4ocx8nEiWTSlkSJomhTFC1CvAEScW0AfcGzf5zTYBNsAI3uPugG+vep6gL79Gn0I4j88eVz3vO+5u6IiMjKa2t0ASIirUoBLCLSIApgEZEGUQCLiDSIAlhEpEHijS6gnvbu3evf/OY3G12GiMh8Vu7gmhoBDw8PN7oEEZGKrakAFhFZTRTAIiINogAWEWkQBbCISIMogEVEGkQBLCLSIApgEZEGUQCLiDSIAlhEpEEUwCIiDaIAFhFpEAWwiEiDKIDr6HtvvMP/+5fHG12GiKwSCuA6+tLzP+YPvn2Cl06PNLoUEVkFFMB1dPzcOAB/8tyPG1yJiKwGCuA6yRVmeX1ogvaY8RcvneHiZLbRJYlIk1MA18kbw5PkCs69t13NTH6W506+3eiSRKTJKYDr5LWw/XDn7k0AnB+bbmQ5IrIKKIDr5Ifnxom1Gf/omnXE24wL4zONLklEmpwCuE5eOzfOzg1pOtpjbOhKKoBFZEkK4Dr50YVxrtvUDcCmnqRaECKyJAVwnVwYm2FLbwcAA90dDGkELCJLUADXwXSuwFSuQH86AcDGHrUgRGRpCuA6GMnkAOhPBQG8qbuDdyazZPOzjSxLRJqcArgOLmaCmy76U+1AMAIGGJrQKFhEFqYAroNiAPcVR8BhAF/QhTgRWYQCuA4uToYtiHQ4Au4OLsadH9MIWEQWpgCug0stiPAiXHfYghjXCFhEFqYAroORuRZEMAJe35WkzdBMCBFZlAK4Di5mcqQSMZLxGACxNmNDl27GEJHFRRrAZrbXzI6b2Qkze7jM62Zmnw1fP2Jmt4bHrzOzF0seY2b2qShrrcXFTHau/VC0Lp2Ym54mIlJOPKpvbGYx4BHgTmAQOGRmB9z91ZLT7gJ2hY/bgUeB2939OHBzyfd5C/h6VLXWaiSTm7sAV9TT0c7YtAJYRBYW5Qj4NuCEu5909yzwFLBv3jn7gCc98BzQZ2Zb5p3zEeB1d2/abSbKjYC7O+KMT+cbVJGIrAZRBvBW4HTJ88Hw2HLPuQf4ct2rq6OLk9m5OcBFPZ0aAYvI4qIMYCtzzJdzjpklgE8A/3XBDzHbb2aHzezw0NBQVYXW6mImN3cXXFF3R5yxKY2ARWRhUQbwILC95Pk24Mwyz7kL+IG7n1/oQ9z9cXff4+57BgYGaix5+Qqzzth07soRcEc749M53Of/nSMiEogygA8Bu8xsZziSvQc4MO+cA8B94WyIO4BRdz9b8vq9NHn7YXQqhztlR8CzDpPZQoMqE5FmF9ksCHfPm9lDwDNADHjC3Y+a2QPh648BB4G7gRNABri/+H4zSxHMoPjnUdVYD/Pvgivq6QwCeXw6R1cysh+ziKxikSaDux8kCNnSY4+V/NqBBxd4bwZYH2V99TD/Lriino7g+dhUni29K16WiKwCuhOuRmPhVLPiiLeouyP4u21cMyFEZAEK4BpNzgQBPL/NUAxkTUUTkYUogGtUDOD0vAC+NALWVDQRKU8BXKOJmWCWQ1di3gh4rgesEbCIlKcArtGlEXDssuPFEfCYRsAisgAFcI0mZ/Ik423EY5f/KDvaYyTibeoBi8iCFMA1mpjJLzjPN7gbTiNgESlPAVyjyZn8FRfgino64uoBi8iCFMA1mpgpLBjA3Z3t6gGLyIIUwDWanMnTNe8CXFFPR1w3YojIghTANZrMLtaCaFcLQkQWpACu0cQiPWDtiiEii1EA12hyJn/FTRhF2hVDRBajAK7R5CIX4bqScaZzs+QKsytclYisBgrgGrg7k9mFL8IVgzmjRdlFpAwFcA0y2QLuVy7EU5ROxMLz1AcWkSspgGuw0EpoRanw+OSMRsAiciUFcA0mFlgLuKg4Ai4GtYhIKQVwDYoj2wVHwOHsiEm1IESkDAVwDZYaARePZ9SCEJEyFMA1WCqAU+HsCI2ARaQcBXANFlqMvSid0EU4EVmYArgGlY6ANQ1NRMpRANdgqWloGgGLyGIUwDWYnMljBqlE+RZErM3oaG9TD1hEylIA12BipkA6EcfMFjwnnYhrHrCIlKUArkEmm19w9FuUSsa0FoSIlKUArsFUrrBkAGsELCILUQDXYCpboKN9iQBOxtUDFpGyFMA1mMoV6FyqBZGIaRaEiJQVaQCb2V4zO25mJ8zs4TKvm5l9Nnz9iJndWvJan5l91cxeM7NjZvb+KGutxlS2shaE5gGLSDmRBbCZxYBHgLuA3cC9ZrZ73ml3AbvCx37g0ZLXPgN8092vB24CjkVVa7WmcgU6K2lBaAQsImVEOQK+DTjh7ifdPQs8Beybd84+4EkPPAf0mdkWM+sBPgh8HsDds+4+EmGtVZnKVdIDjqkHLCJlRRnAW4HTJc8Hw2OVnHMtMAT8kZm9YGafM7N0uQ8xs/1mdtjMDg8NDdWv+gpU0oJIJeJaDU1EyooygMvdneAVnhMHbgUedfdbgEngih4ygLs/7u573H3PwMBALfUuW0UtiESMbGGWbF4bc4rI5aIM4EFge8nzbcCZCs8ZBAbd/fnw+FcJArmpTGULdCx1EW5uY061IUTkclEG8CFgl5ntNLMEcA9wYN45B4D7wtkQdwCj7n7W3c8Bp83suvC8jwCvRljrss3OOjP52QouwhXXBFYbQkQuV34Zrzpw97yZPQQ8A8SAJ9z9qJk9EL7+GHAQuBs4AWSA+0u+xa8CXwrD++S81xpuKhcEaiU9YICM7oYTkXkiC2AAdz9IELKlxx4r+bUDDy7w3heBPVHWV4tiAGsELCLV0p1wVZoKA3XJaWhzawJrBCwil1MAV+lSC2Lxf0QUL8IpgEVkPgVwlYoj4M7E4j/CYo9YS1KKyHwK4CoVR8BLtSDmLsIpgEVkHgVwlSq9CNeZ0MacIlKeArhKxRbEUj1gtSBEZCEK4CrN9YCXGAG3x9pIxNoUwCJyBQVwleZ6wEtchIOgDTGlFoSIzKMArlKlLYjgnJhuxBCRKyiAqzQ3Ao5XOgJWAIvI5RTAVZrKFUjE2ojHlv4RphIxzYIQkSsogKsU7Ihc2Y8vlYjrIpyIXEEBXKVgN4zK1jIKRsAKYBG5nAK4SpVsSV+kFoSIlKMArlIlG3IWdbbHdRFORK6gAK5SJRtyFqWTMTI5BbCIXE4BXKVKNuQs6lQPWETKUABXKZgFUWEPuD1ONj9LvqCdkUXkEgVwlaaXeREOUBtCRC6jAK5SJlsgVekIONwXThfiRKSUArhKy52GBlqSUkQupwCu0nKnoYH2hRORyymAq1CYdbL52YqnoRXPm1IPWERKKICrUOl2REXppFoQInIlBXAVihfTOiocARdbEFqUXURKKYCrML3MEXCxBTE5oxGwiFyiAK5CZm43DM0DFpHqKYCrsNwecHG6mloQIlJKAVyFuR5wxS2IoAesi3AiUkoBXIViD7jSFkSszUjG23QnnIhcJtIANrO9ZnbczE6Y2cNlXjcz+2z4+hEzu7XktVNm9rKZvWhmh6Osc7mKI9lK74SD4s7IakGIyCWV7alTBTOLAY8AdwKDwCEzO+Dur5acdhewK3zcDjwafi36kLsPR1VjtZbbAwbtCyciV4pyBHwbcMLdT7p7FngK2DfvnH3Akx54Dugzsy0R1lQXc1vSLyuAtTW9iFwuygDeCpwueT4YHqv0HAf+0sy+b2b7F/oQM9tvZofN7PDQ0FAdyl5acTZDpT3g4rkaAYtIqSgD2Moc82Wc8wF3v5WgTfGgmX2w3Ie4++Puvsfd9wwMDFRf7TJMZYOF1ZczAu7UxpwiMk+UATwIbC95vg04U+k57l78egH4OkFLoylM5Qok4m3E2sr9/VGeesAiMl+UAXwI2GVmO80sAdwDHJh3zgHgvnA2xB3AqLufNbO0mXUDmFka+BjwSoS1Lst0rvINOYvUAxaR+SKbBeHueTN7CHgGiAFPuPtRM3sgfP0x4CBwN3ACyAD3h2/fBHzdzIo1/qm7fzOqWpcrk80vawYEqAcsIleKLIAB3P0gQciWHnus5NcOPFjmfSeBm6KsrRZTudkqAjiuecAichndCVeF5eyIXNSpFoSIzKMArsJULr/8HnB7jHy4k4aICCiAqzKVrXxDzqJUsrgou0bBIhJQAFdhKje77BbE3KLs6gOLSEgBXIVqp6GBlqQUkUsUwFWoZhpa8Xy1IESkSAFchWpmQaSTxUXZ1YIQkYACuArTudllX4Tr1L5wIjKPAniZ8oVZsoVZUlVehMtoZ2QRCSmAl2luMfZlzwNWC0JELqcAXqZqFmMHSCVjl71fREQBvEzT4VrAmoYmIrVSAC9TJhe0EJY7Da0jXuwBqwUhIgEF8DIV5/F2LHME3NZmdLZrSUoRuUQBvEzV7IhclErENA1NROYogJepOAKuKoCTWpJSRC5RAC9TcQS83ItwEExFm1QPWERCCuBlmusBVzEC7kzENA1NROYogJepphGw9oUTkRIVBbCZPW1mP2tmLR/Ycz3gqgJYW9OLyCWVBuqjwP8E/MjM/p2ZXR9hTU1t7k64eHUj4CndiiwioYoC2N2/5e6/CNwKnAKeNbO/N7P7zaw9ygKbTbAUZRttbbbs96YSMSY1AhaRUMUtBTNbD/wy8L8ALwCfIQjkZyOprElN5QpVTUED7YwsIpeLV3KSmX0NuB74E+Dn3f1s+NJ/MbPDURXXjKay1QdwOhEnk83j7pgtfwQtImtLRQEMfM7dD5YeMLOku8+4+54I6mpamdzyd0Qu6kzEmHWYyS9/U08RWXsqbUH8bplj/1DPQlaL6Sq2pC/SimgiUmrREbCZbQa2Ap1mdgtQ/HdzD5CKuLamVEsP+FIA51mXTtSzLBFZhZZqQXyc4MLbNuD3So6PA78ZUU1NLZMt0NNZ3cSPVCL4cetCnIjAEgHs7l8AvmBm/527P71CNTW16VyBTT3Jqt6rFoSIlFqqBfFJd/8icI2Z/W/zX3f33yvztjWt1mloAJO6GUNEWPoiXDr82gV0l3ksysz2mtlxMzthZg+Xed3M7LPh60fM7NZ5r8fM7AUz+0ZF/zUrIJMt0JmodPLI5dSCEJFSS7Ug/jD8+jvL/cZmFgMeAe4EBoFDZnbA3V8tOe0uYFf4uJ3glufbS17/NeAYwUW/pjBdwzxgtSBEpFSli/H8ezPrMbN2M/srMxs2s08u8bbbgBPuftLds8BTwL555+wDnvTAc0CfmW0JP3Mb8LPA55b1XxSxqVyBzkR1axIVA1gjYBGByucBf8zdx4CfIxjNvgf410u8ZytwuuT5YHis0nP+I/AbwOxiH2Jm+83ssJkdHhoaWqKk2mTzs+Rnfa6VsFzF96kHLCJQeQAX513dDXzZ3d+p4D3l7rX1Ss4xs58DLrj795f6EHd/3N33uPuegYGBCsqq3txKaGpBiEgdVBrAf2FmrwF7gL8yswFgeon3DALbS55vA85UeM4HgE+Y2SmC1sWHzeyLFdYamekaNuQESMbbMFMLQkQClS5H+TDwfmCPu+eASa7s5853CNhlZjvNLAHcAxyYd84B4L5wNsQdwKi7n3X3T7v7Nne/Jnzft919qZ5z5Ioj12p2wwAws3BBHgWwiFS+GA/ADQTzgUvf8+RCJ7t73sweAp4BYsAT7n7UzB4IX38MOEjQ1jgBZID7l1n/iqplP7iiYF849YBFpPLlKP8EeBfwIlAcvjmLBDBAuILawXnHHiv5tQMPLvE9vgN8p5I6o1bsAVe7GA+Ei7LPaAQsIpWPgPcAu8PAbFnTNWzIWdTZro05RSRQ6UW4V4DNURayGhSDs9qLcADpZFwtCBEBKh8BbwBeNbPvATPFg+7+iUiqalK1TkODYPQ8MaMAFpHKA/i3oyxitZiucRYEBKPnC2MzS58oImteRQHs7n9jZjuAXe7+LTNLEcxsaCmZ8A62WloQqUSMjFoQIkLla0H8M+CrwB+Gh7YCfxZRTU1rKhfcFV3LLIjORFw3YogIUPlFuAcJ7k4bA3D3HwEboyqqWU3lCpgFd7RVK53QLAgRCVSaJDPhimYAhDdjtNyUtKlsns72WE1byqfCAJ6dbbkfn4jMU2kA/42Z/SbB5px3Av8V+IvoympOteyGUVRczH06r1GwSKurNIAfBoaAl4F/TnB32/8ZVVHNaio7W9MUNNCKaCJySaWzIGbN7M+AP3P3aBfdbWJTuXxNU9BAi7KLyCWLjoDDVcp+28yGgdeA42Y2ZGb/18qU11ymsoWaZkDApUXZNQIWkaVaEJ8imP3wj9x9vbuvI9iz7QNm9q+iLq7ZTOUKdWtBaFcMEVkqgO8D7nX3N4oH3P0k8MnwtZYylS3U3ILoVAtCREJLBXC7uw/PPxj2gdvLnL+m1WMWRFotCBEJLRXA2SpfW5PqMw2tOAtCLQiRVrfULIibzGyszHEDOiKop6nV5yKcpqGJSGDRAHb3lltwZzFT2dpHwF0d4db0WpJSpOVVv6hBi3H3oAVR4wi42AMen1YAi7Q6BXCFZvKzzHptK6EBxNqMzvaYRsAiogCuVHE/uFpbEBC0ITQPWEQUwBWaqmcAJ+NqQYiIArhScxty1tiCgCCA1YIQEQVwhabqsCNyUTqpjTlFRAFcsbkecJ1GwBMzmgcs0uoUwBXK1GFH5CK1IEQEFMAVK16Eq3U1NIB0Mq4WhIgogCtV12loCmARQQFcsUstiIo2EVlUVzJONj9LNj9b8/cSkdVLAVyh+s6C0HoQIhJxAJvZXjM7bmYnzOzhMq+bmX02fP2Imd0aHu8ws++Z2UtmdtTMfifKOisx1wNO1P4jKy7IozaESGuLLIDNLAY8AtwF7AbuNbPd8067C9gVPvYDj4bHZ4APu/tNwM3AXjO7I6paKzGVLRBrMxKxOgRwUgEsItGOgG8DTrj7SXfPAk8B++adsw940gPPAX1mtiV8PhGe0x4+PMJal1RcjN3Mav5eakGICEQbwFuB0yXPB8NjFZ1jZjEzexG4ADzr7s+X+xAz229mh83s8NDQUL1qv0I9NuQs0ghYRCDaAC43VJw/il3wHHcvuPvNwDbgNjN7b7kPcffH3X2Pu+8ZGBiopd5F1WNDziIFsIhAtAE8CGwveb4NOLPcc9x9BPgOsLfuFS5DPXbDKEonw63pFcAiLS3KAD4E7DKznWaWAO4BDsw75wBwXzgb4g5g1N3PmtmAmfUBmFkn8FHgtQhrXdJUrkBHnUbA3clgQ2ktSSnS2mq/q2AB7p43s4eAZ4AY8IS7HzWzB8LXHwMOAncDJ4AMcH/49i3AF8KZFG3AV9z9G1HVWompbIFU3UfAWpBHpJVFFsAA7n6QIGRLjz1W8msHHizzviPALVHWtlxTuQID3cm6fK94rI2O9jbtiiHS4nQnXIWK09DqRbtiiIgCuEJT2dp3RC6V1pKUIi1PAVyhKEbACmCR1qYArlC9R8BqQYiIArgCs7Ne9xFwT2c7Y9O5un0/EVl9FMAVyIQroRXvYKuHno52xqYUwCKtTAFcgUzYq00l6zcC7u1sZ0wtCJGWpgCuQHHNhnQddsMo6ukMtiXKF7QrhkirUgBXoLgdUbrOLQjQgjwirUwBXIHJuRFwfS/CAYxNKYBFWpUCuALFW4brOwIOvpdmQoi0LgVwBYqL5qTreBGuOAIe1UwIkZalAK5AJhwB12NL+qJiD1hT0URalwK4AhMz9b8I15sKA1gtCJGWpQCuwNw84HpehCv2gHURTqRlKYArMJHNk4i30V6HLemL0ok4baYRsEgrUwBXIDNTqOttyABtbUa3bkcWaWkK4ApMZvN1bT8U9XTGdTuySAtTAFdgciZf19uQi7Qgj0hrUwBXIJMt1HUOcFFPR7vmAYu0MAVwBSZn8nWdglbUqzWBRVqaArgCkzOF6HrAmoYm0rIUwBWYzEYzAu7p0AhYpJUpgCsQ2UW4znYy2QI5rQks0pIUwBWYzBYiGgEH31MX4kRakwJ4CbnCLNn8bF3XAi7qTycAGMlk6/69RaT5KYCXkAkX4klFMAJen04C8PaEAlikFSmAl1BcjL0rgnnA/elgRbSLGgGLtCQF8BKiWAu4aG4EPKkAFmlFCuAlTESwG0bR3AhYASzSkiINYDPba2bHzeyEmT1c5nUzs8+Grx8xs1vD49vN7K/N7JiZHTWzX4uyzsVkItiSvigZj9GVjGsELNKiIgtgM4sBjwB3AbuBe81s97zT7gJ2hY/9wKPh8Tzw6+5+A3AH8GCZ966IyQi2pC+1Lp3QCFikRUU5Ar4NOOHuJ909CzwF7Jt3zj7gSQ88B/SZ2RZ3P+vuPwBw93HgGLA1wloXNDETzNGNKoD70wmNgEVaVJQBvBU4XfJ8kCtDdMlzzOwa4Bbg+XIfYmb7zeywmR0eGhqqteYrFNdq6O6IJoDXpxO8owAWaUlRBrCVOebLOcfMuoCngU+5+1i5D3H3x919j7vvGRgYqLrYhYyHazVEFcBqQYi0rigDeBDYXvJ8G3Cm0nPMrJ0gfL/k7l+LsM5FjU/nScbbSMbrPwsCggB+ezKL+/y/m0RkrYsygA8Bu8xsp5klgHuAA/POOQDcF86GuAMYdfezZmbA54Fj7v57Eda4pLHpPN0d7ZF9/3XpBDP5WaZyhcg+Q0SaUzT/rgbcPW9mDwHPADHgCXc/amYPhK8/BhwE7gZOABng/vDtHwD+Z+BlM3sxPPab7n4wqnoXMj6dm1s0JwrrUsF6EG9PZEmti+5zRKT5RPonPgzMg/OOPVbyawceLPO+v6N8f3jFjU/nI+v/QjAChuB25O3rUpF9jog0H90Jt4Tx6Vy0LYiucASsC3EiLUcBvITIR8BhC+IdrYgm0nIUwEuIOoDXhyPg4YmZyD5DRJqTAngJUbcgupJx0okY58cUwCKtRgG8iMKsM5ktRDoCNjM29XZwbmwqss8QkeakAF7ExHTxNuToRsAAW3o7ODc6HelniEjzUQAvYizi25CLNvV0qAUh0oIUwIsoBnCUN2IAbO7p4PzYNLOzuh1ZpJUogBcxvoItiPysMzypUbBIK1EAL+JSAEffggDUBxZpMQrgRVxaijLaEfDmXgWwSCtSAC9ipUbAxQA+P6YAFmklCuBFRL0Ye9GGdJJ4m3FWI2CRlqIAXkTUi7EXtbUZG7uTnNMIWKSlKIAXEfVi7KU262YMkZajAF5E1Iuxl9q+LsWb72RW5LNEpDkogBcxOpWjp3NlRsA7N6R5a2SKaW1NJNIyFMCLuJjJzu1YEbWdG9K4o1GwSAtRAC/i4mSOvtTKjICv3dAFwMmhyRX5PBFpPAXwIi5msvSnVmYEfM2GYD+4N4YVwCKtQgG8gOlcgUy2sGItiO6Odga6k5wcmliRzxORxlMAL2AkE9yEsVItCAj6wBoBi7QOBfACLmaCTTJXqgUB8K4BBbBIK1EAL+Di5MoH8M4Nad6ezDIajr5FZG1TAC/gYhiC/emVa0Fct7kHgKNnRlfsM0WkcRTAC2hEC+Kmbb0AvHB6ZMU+U0QaRwG8gGILYiUvwvWlEuzckOZFBbBIS1AAL+BiJkc6EYt8JbT5bt7ex4unR3DX/nAia50CeAEXM1n6V2gOcKmbt/cxND7DGa2MJrLmKYAXsJJ3wZW6eXsfAC++ObLiny0iKyvSADazvWZ23MxOmNnDZV43M/ts+PoRM7u15LUnzOyCmb0SZY0LuZhZuXUgSt2wpYdUIsZ3Xx9e8c8WkZUVWQCbWQx4BLgL2A3ca2a75512F7ArfOwHHi157Y+BvVHVt5SLkyu3ElqpRLyNn7lugGdfPc/srPrAImtZlCPg24AT7n7S3bPAU8C+eefsA570wHNAn5ltAXD3vwXeibC+RTWqBQHw8Rs3MzQ+wwunLzbk80VkZUQZwFuB0yXPB8Njyz1nUWa238wOm9nhoaGhqgqdL1eYZXw635AWBMCHrt9Ie8x45uj5hny+iKyMKAPYyhyb/2/qSs5ZlLs/7u573H3PwMDAct66oOGJGQA2dnfU5fstV09HOx949wYOvHiGbH62ITWISPSiDOBBYHvJ823AmSrOWXHFzTE39SQbVsP9H9jJubFpvv7CYMNqEJFoRRnAh4BdZrbTzBLAPcCBeeccAO4LZ0PcAYy6+9kIa6rI+bFgBLyppzEjYIAP7trAT2zt5dHvvE6+oFGwyFoUWQC7ex54CHgGOAZ8xd2PmtkDZvZAeNpB4CRwAvjPwL8svt/Mvgz8A3CdmQ2a2a9EVet8F8aDEfDGBo6AzYxf/fC7OfV2hsf+5vWG1SEi0Yl0z3V3P0gQsqXHHiv5tQMPLvDee6OsbTHnx6aJtRkb0o0LYIA7d2/i52+6it//1o+449r17LlmXUPrEZH60p1wZZwfm2Fjd5K2tnLXCFeOmfG7v/BetvV3cv8fHeLwqYbNyhORCCiAyzg/Ns3GBvZ/S/V2tvPU/jsY6E5y739+jke/8zo59YRF1gQFcBnnx6bZ1N3Y9kOpLb2dPP0vfoqP3rCJ/+ebr/Gx3/9bvnLoNFPZQqNLE5EaKIDLOD82w+be5hgBF/WnE/ynX7yVz//SHpLxNn7j6SPc9m++xW8fOMqhU+9Q0G3LIqtOpBfhVqPpXIHRqVxDp6AtxMz4yA2b+PD1Gzl06iJfev7H/Onzb/LHf3+K/lQ7H3zPAHt29HPL1f1cv7mbeEx/v4o0MwXwPBfGinfBNU8LYj4z47ad67ht5zp+9xdy/O0Ph/nWsfP8tx8N8+cvBvexpBIxfmJrLzds6eGGLd1cv7mH92zqpjOxsgvMi8jCFMDznBsL5gA3WwtiId0d7fzs+7bws+/bgrszeHGKH7x5kRfeHOGlwRG+cvg0mbBXbAY716e5fks3N2zu4fotPVy/uZtt/Z2YNXbGh0grUgDPcz4M4EatA1ELM2P7uhTb16XYd3OwptHsrHP6YoZjZ8d57dwYr50d5+iZMQ6+fG7ufd3JONdt7g6CeUtPOFruorujMYsRibQKBfA8b76TAWBbf2eDK6mPtjZjx/o0O9an2fvezXPHJ2fyHD8/zmslwfznL57hi8+9OXfOhq4EO9anuWZ9mp0bUuxYn+aqvk6u6utgY3cHsQbPkxZZ7RTA85wanmRjd5J0cm3/aNLJOLde3c+tV/fPHXN33hqZ4tjZcV4fmuDU8CRvDE/ydyeGePoHM5e9P9ZmbOpOsqWvky29HWzu6aA/naA/laA/1U5fKkF/up1ErI32WBuxNiPeZmQLs0znZpnJF+a+zuRnmcnNMutOYdaZDTck7WiP0dkeI5WI0ZmI0Z1sp6sjTlcyTiKuC4yy+q3tlKnCG8OTXLMh3egyGsLM2NafYlt/ijvZdNlrmWyeH7+d4ezoFGdHpzk7Ms2Z0SnOjkzzylujfPu1C3O95pWQjLfRHYZxV0d8Lpy7k3HSyTipRIyO9lgY4m10hs/7Ugk29STZ3NNBb2e7et/SUArgeU69PclHb9i09IktJpWIhzMqehY8ZzpXYCST42Imy8VMlpFMjlxhllzByRdmyc86iXgbyXgbyXiMjvZLXxPxYJQcM5u7BXwqW2A6VyCTLZDJ5pmYKTAxnWN8Os/ETJ7xmTwT03nGp3NMzOQ5/U6G8ek8k9k807lghL2YZLyN7etSXL+5O3z0sPuqHrb0diiYZUUogEuMTecYnsi27Ai4Vh3tMTb3xppmBsnsrDOTn2UqVwge2QIjmSznxqY5PzbD+bFp3hie5KXBEb5x5NIqqBu6kty0rZef2NbLTdv6eN+2XtZ3Ne+0RFm9FMAlTg1PAnDNegXwWtDWZnSG/eOlTMzkOX5ujKNnxnjp9ChHBkf49vELhO1otvZ1ctP2Xt4XBvJPbO3VLBGpmQK4xBthAO/UCLjldCXj/OSOdfzkjnXw/uDYxEyeV94KwvilwVFeHhydm75nBtduSM8F8vu29XHjVT10tOtGF6mcArjEG8OTmMGO9alGlyJNoCsZ545r13PHtevnjl2czHLkrVGOnA5C+bsnhvn6C28BEG8z3rOpe26kvHtLD+/a2EXXGp9RI9XT74wSp4Ynuaq3U6MYWVB/OsFPv2eAn37PpQ1gz41O89LgCC8PjvLS4AgHXz7Hl793abPvLb0dvHtjF1evSzHQnWRjdwcD3UnWdyXo6wym7PV0xLV2RwtSAJd47dw4797Y1egyZJXZ3NvB5t7NfPzG4EYXd+fNdzK8dm6cExcm5h5Hz5zjncnsgt+nOxmnN9VOX6qd3s52+joTwfPO4Fh/KsHGng429QQh3p/SNLrVTgEcmgjvDCv+IRKpltmluw8/fuPlr+UKswxPzHBhbIZ3MllGMzlGMllGpnKMTuWC51PBsbOjY4xmguP5MsuNJmJtwYi6J8nG7iSbejrY1BOMrjf1dMwdU1A3LwVw6MjgCO5wy9V9jS5F1rD2WBtbejvZ0lv5re7uzmS2wNsTM1wYD8L7/Nh0+Ovg68mhSZ47+Q6jU7kyn2lzbY/i6HlTT5KNYUivTyfpTwcj7FQiprBeQQrg0AtvjgBw8/a+htYhMp+ZBXf8JePsWGKK5HSuwND4pYAu/To0PsMbwwsHNQSj6mIYr0sn2Nbfyfb+FFevT3H1uhS7NnXromId6ScZevH0CNduSNOXSjS6FJGqdbTH5lbEW0wxqC+MT/POZI6Lk8Hdi+9ksoxM5ngnk+XtiRm+c3yIC+OXrwOyY30qXM40WD3vxqt62NqnJU2roQAm+CfeC2+O8MFdGxpdisiKqDSoIQjrwYsZ3hjOcPzcGMfOjnPs7BjPvHpu7kaVvlQ7N17Vw41X9XLjVT28d2svO9enG76zeLNTAAMnLkwwPDHDrTv6lz5ZpMV0tMd498Zu3r2xmzt3X1onJZPNc/xcsL508Bjlj797imy4a3cqEWN3OEK+cWsQzLs2dmsluxIKYOAvjpylzeBjN2oRHpFKpRJxbrk62IOwKFeY5cSFCV55a3QulL/6/UG+8A8/BoIe83Wbu+dC+b1XBQs8terc+5YPYHfnG0fOcPvO9atyFwyRZtIea5tbNe9/CI/Nzjqn3p7k6JkxXjkzyqtnxnjm6DmeOhTcrBJrM3Zt7OLGq3p579agfbF7S8+aX5MbFMAcOzvOyaFJfuUf72x0KSJrUlubce1AF9cOdPHzN10FBAOfM6PBWtJH3xrl5bdG+ZsfDvH0DwaBS2tt/OSO/rnbwa/qWxu71JRq+QD+/N+9QSLexl7dgCGyYsyMrX2dbO3rvOzmp/NjQSi/8tYYL781wjNHz/OVw0Eo71if4p/s2sCduzdzx7XrSMZXf9uipQP4lbdG+doLg+z/4LVa71WkCRTv5vtIuCnC7Kzz2rlxnjv5Nn//+ts8/f23+OJzb9KVjPPT7xngzt2b+NB1G+lNrc6lQc39ylscV6s9e/b44cOHKzrX3fnFzz3PsbNjfOdff4jeztX5P1CklUznCnz3xDDfOnaeZ1+9wPDEDLE24/ad67hz9ybu3L2Jbf1NuZph2fl4kQawme0FPgPEgM+5+7+b97qFr98NZIBfdvcfVPLecpYbwP/fy2fJFWb5p7dsW8Z/lYg0g9lZ58XBEZ599TzPvnqeExcmALh+czfvf9d6fupdG9izo5/+dFPcXLWyAWxmMeCHwJ3AIHAIuNfdXy05527gVwkC+HbgM+5+eyXvLWc5ASwia8sbw5M8++o5vnN8iO//+CIz+WA+8pbeDnZv6eGaDWm29QfrcPSl2unpaKenM9jQNR6zuZ27Y20WxV19Zb9hlD3g24AT7n4SwMyeAvYBpSG6D3jSg78FnjOzPjPbAlxTwXtFRObs3JBm/wffxf4PvouZfIEX3hzhyOAIR8+McezsGN99fXjJjVqLYmEQtxlYmJ1m0N0R5/nf/Gjdao4ygLcCp0ueDxKMcpc6Z2uF7wXAzPYD+8OnE2Z2vIaa62EDMNzgGqqxGutejTWD6l5Jda/Zfquqt33T3ffOPxhlAJcbcs/vdyx0TiXvDQ66Pw48vrzSomNmh919T6PrWK7VWPdqrBlU90pq9pqjDOBBYHvJ823AmQrPSVTwXhGRVS3KVTEOAbvMbKeZJYB7gAPzzjkA3GeBO4BRdz9b4XtFRFa1yEbA7p43s4eAZwimkj3h7kfN7IHw9ceAgwQzIE4QTEO7f7H3RlVrnTVNO2SZVmPdq7FmUN0rqalrXlM3YoiIrCZamFNEpEEUwCIiDaIArhMz22tmx83shJk93Oh6FmJm283sr83smJkdNbNfC4+vM7NnzexH4dem2x7EzGJm9oKZfSN8vhpq7jOzr5rZa+HP/P2rpO5/Ff7+eMXMvmxmHc1Yt5k9YWYXzOyVkmML1mlmnw7/jB43s483pupLFMB1EN46/QhwF7AbuNfMdje2qgXlgV939xuAO4AHw1ofBv7K3XcBfxU+bza/Bhwreb4aav4MwST864GbCOpv6rrNbCvwvwJ73P29BBfC76E56/5jYP4NDmXrDH+f3wPcGL7nP4V/dhvH3fWo8QG8H3im5PmngU83uq4Ka/9zgjU3jgNbwmNbgOONrm1endsI/jB9GPhGeKzZa+4B3iC82F1yvNnrLt6Juo5gptQ3gI81a90ESxe8stTPd/6fS4JZVu9vZO0aAdfHQrdUNzUzuwa4BXge2OTBHGzCrxsbWFo5/xH4DaD0Zv5mr/laYAj4o7B18jkzS9Pkdbv7W8B/AN4EzhLMz/9LmrzuEgvV2XR/ThXA9VHxrdPNwsy6gKeBT7n7WKPrWYyZ/Rxwwd2/3+halikO3Ao86u63AJM0xz/bFxX2TPcBO4GrgLSZfbKxVdVF0/05VQDXRyW3XTcNM2snCN8vufvXwsPnw5XoCL9eaFR9ZXwA+ISZnQKeAj5sZl+kuWuG4PfFoLs/Hz7/KkEgN3vdHwXecPchd88BXwN+iuavu2ihOpvuz6kCuD5Wza3T4SL4nweOufvvlbx0APil8Ne/RNAbbgru/ml33+bu1xD8bL/t7p+kiWsGcPdzwGkzuy489BGCJVWbum6C1sMdZpYKf798hODiYbPXXbRQnQeAe8wsaWY7gV3A9xpQ3yWNbqCvlQfBLdU/BF4HfqvR9SxS5z8m+GfXEeDF8HE3sJ7gItePwq/rGl3rAvX/DJcuwjV9zcDNwOHw5/1nQP8qqft3gNeAV4A/AZLNWDfwZYI+dY5ghPsri9UJ/Fb4Z/Q4cFej69etyCIiDaIWhIhIgyiARUQaRAEsItIgCmARkQZRAIuINEiUe8KJrBgzK049AtgMFAhuAwb4OMEUpYfc/Q9L3nMKGCeYlncRuM/dfxy+tgn4fYIFiy4CWeDfu/vXzexnCOaWvlFSwr8lWGug3Off5u7ZOv2nyhqiaWiy5pjZbwMT7v4fwuf/ErgXKLj7z5Scd4pgxa9hM/sd4Cp3/2fhzQd/D3zBg62zMLMdwCfc/Q/CAP7f3f3nKvl8kYWoBSGt4F7g14Ft4VKL5fwDlxZm+TCQLYYvgLv/2N3/INoypdUogGVNM7PtwGZ3/x7wFeB/XODUvQR3qkGwXuwPlvjW/8TMXix5vKsuBUtLUQDLWncPQfBCsJDPvfNe/2szu0CwAM2flvsGZvaImb1kZodKDv83d7+55PF63SuXNU8BLGvdvcAvh/3eA8BNZrar5PUPATuAo8D/HR47SrBqGQDu/iDBgjQDK1GwtA4FsKxZ4SpkaXff6u7XeLCa2r8lGBXPcfcp4FPAfWa2Dvg20GFm/6LktNTKVC2tRAEsa9m9wNfnHXuaK9sQeLBzwpeBBz2YGvQLwE+b2Rtm9j3gC8D/UfKW+T3g/z6S/wJZ0zQNTUSkQTQCFhFpEAWwiEiDKIBFRBpEASwi0iAKYBGRBlEAi4g0iAJYRKRB/n+BKPzZRID4pQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(x=df.TARGET, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variable(df): # 파생변수 생성\n",
    "    # 주차\n",
    "    df['week'] = df['Day'] // 7\n",
    "\n",
    "    # 전체 도달 에너지량 \n",
    "    # (reference: https://www.researchgate.net/post/Why_does_the_solar_data_DNI_DHI_GHI_obtained_from_the_PVGIS_database_not_match_the_euqation)\n",
    "    df['sum_energy'] = df['DHI'] + df['DNI']\n",
    "\n",
    "    # 태양고도\n",
    "    df['theta'] = 0\n",
    "    condition_list = [\n",
    "        (df['Hour'] == 6) | (df['Hour'] == 19),\n",
    "        (df['Hour'] == 7) | (df['Hour'] == 18),\n",
    "        (df['Hour'] == 8) | (df['Hour'] == 17),\n",
    "        (df['Hour'] == 9) | (df['Hour'] == 16),\n",
    "        (df['Hour'] == 10) | (df['Hour'] == 15),\n",
    "        (df['Hour'] == 11) | (df['Hour'] == 14),\n",
    "        (df['Hour'] == 12) | (df['Hour'] == 13)\n",
    "    ]\n",
    "\n",
    "    choice_list = [0,10,20,30,40,50,60]\n",
    "\n",
    "    df['theta'] = np.select(condition_list, choice_list)\n",
    "\n",
    "    # GHI\n",
    "    df['GHI'] = df['DNI'] * np.cos(df['theta']) + df['DHI']\n",
    "    \n",
    "    #Td\n",
    "    c = 243.12\n",
    "    b = 17.62\n",
    "    gamma = (b * (df['T']) / (c + (df['T']))) + np.log(df['RH'] / 100)\n",
    "    dp = (c * gamma) / (b - gamma)\n",
    "    df.insert(1,'Td',dp)\n",
    "    df.insert(1,'T-Td', df['T']-df['Td'])\n",
    "    \n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "\n",
    "def preprocess(path, delay, add_var): # 데이터 전처리\n",
    "    df = pd.read_csv(path).copy()\n",
    "    \n",
    "    if delay == 1:\n",
    "        df1 = df[:-48] # 2일씩 delay 시킨 데이터\n",
    "        df1 = df1.drop('TARGET', axis = 1)\n",
    "        df1['TARGET'] = df['TARGET'].loc[48:].values\n",
    "        if add_var == False:\n",
    "            pass\n",
    "        else:\n",
    "            df1 = add_variable(df1)\n",
    "        return pd.DataFrame(df1)\n",
    "\n",
    "    elif delay == 2:\n",
    "        df2 = df[:-96] # 2일씩 delay 시킨 데이터\n",
    "        df2 = df2.drop('TARGET', axis = 1)\n",
    "        df2['TARGET'] = df['TARGET'].loc[96:].values\n",
    "        if add_var == False:\n",
    "            pass\n",
    "        else:\n",
    "            df2 = add_variable(df2)\n",
    "        return pd.DataFrame(df2)\n",
    "    else:\n",
    "        df = df.drop('TARGET', axis=1)\n",
    "        if add_var == False:\n",
    "            pass\n",
    "        else:\n",
    "            df = add_variable(df)\n",
    "        return pd.DataFrame(df)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "def data_split3(df, split): # train:valid:test 로 split\n",
    "    X = df.drop('TARGET', axis=1)\n",
    "    y = df['TARGET']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = False)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, shuffle = False)\n",
    "    \n",
    "    if split == 'valid':\n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    elif split == 'test':\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = preprocess('../00_data/train/train.csv', delay = 1, add_var = True)\n",
    "df2 = preprocess('../00_data/train/train.csv', delay = 2, add_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train1, X_valid1, X_test1, y_train1, y_valid1, y_test1 = data_split3(df1, 'valid')\n",
    "#X_train2, X_valid2, X_test2, y_train2, y_valid2, y_test2 = data_split3(df2, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = data_split3(df1, 'test')\n",
    "X_train2, X_test2, y_train2, y_test2 = data_split3(df2, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'metric': 'quantile',\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 15,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'boosting_type': 'gbdt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = np.arange(0.1, 1, 0.1)\n",
    "global quantile\n",
    "y_preds = []\n",
    "\n",
    "def model_training(q, X_train, y_train, X_test):\n",
    "    #print('prediction of quantile', q)\n",
    "    lgb = LGBMRegressor(alpha=q, **params)\n",
    "    model = lgb.fit(X_train, y_train)\n",
    "    pred = pd.Series(model.predict(X_test).round(2))\n",
    "    \n",
    "    return pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(X_train, y_train, X_test):\n",
    "    model_list = []\n",
    "    predict = pd.DataFrame()\n",
    "\n",
    "    for q in quantile:\n",
    "        q = round(q, 2)\n",
    "        pred, model = model_training(q, X_train, y_train, X_test)\n",
    "        model_list.append(model)\n",
    "        predict = pd.concat([predict, pred], axis=1)\n",
    "\n",
    "    predict.columns=quantile\n",
    "    \n",
    "    return model_list, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quantile_loss(y_true, y_pred, quantile):\n",
    "    residual = y_true - y_pred\n",
    "    loss = np.mean(np.maximum(quantile * residual, (quantile - 1) * residual))\n",
    "    print('quantile {} - loss : {}'.format(quantile, loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(y_test, result):\n",
    "    for j,k in enumerate(quantile):\n",
    "        loss = 0\n",
    "        loss += compute_quantile_loss(y_test.values, result.iloc[:, j], quantile = k)\n",
    "    print('=====================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_result(X_train, y_train, X_test):\n",
    "    print('learning...')\n",
    "    models, result = predict_result(X_train, y_train, X_test)\n",
    "    print('done...')\n",
    "    \n",
    "    result[result < 0]=0\n",
    "    hour = X_test.Hour.reset_index(drop=True).copy()\n",
    "    result = pd.concat([result, hour], axis=1)\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        if (result['Hour'].iloc[i] < 6) | (result['Hour'].iloc[i] > 20):\n",
    "            result.iloc[i, :] == 0\n",
    "\n",
    "    result = result.drop('Hour', axis=1)\n",
    "    \n",
    "    return models, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning...\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "models1, result1 =  final_result(X_train1, y_train1, X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile 0.1 - loss : 1.4955171737396848\n",
      "quantile 0.2 - loss : 2.7259408285293585\n",
      "quantile 0.30000000000000004 - loss : 3.461549801826979\n",
      "quantile 0.4 - loss : 4.336756038741458\n",
      "quantile 0.5 - loss : 4.408989881416778\n",
      "quantile 0.6 - loss : 4.385096384690327\n",
      "quantile 0.7000000000000001 - loss : 4.308208162966486\n",
      "quantile 0.8 - loss : 4.588373096779802\n",
      "quantile 0.9 - loss : 3.1146716788849647\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "final_loss(y_test1, result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning...\n",
      "done...\n",
      "quantile 0.1 - loss : 1.5379518661290794\n",
      "quantile 0.2 - loss : 2.573764909396072\n",
      "quantile 0.30000000000000004 - loss : 3.4356298640990666\n",
      "quantile 0.4 - loss : 3.9068959185686625\n",
      "quantile 0.5 - loss : 3.7971639283676324\n",
      "quantile 0.6 - loss : 4.299860177088278\n",
      "quantile 0.7000000000000001 - loss : 4.001399761399436\n",
      "quantile 0.8 - loss : 3.61138591626118\n",
      "quantile 0.9 - loss : 2.349287605015262\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "models2, result2 =  final_result(X_train2, y_train2, X_test2)\n",
    "final_loss(y_test2, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>T-Td</th>\n",
       "      <th>Td</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>week</th>\n",
       "      <th>sum_energy</th>\n",
       "      <th>theta</th>\n",
       "      <th>GHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.876055</td>\n",
       "      <td>-13.876055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>34.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.976610</td>\n",
       "      <td>-13.876610</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>34.17</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13.966234</td>\n",
       "      <td>-13.766234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>34.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.063821</td>\n",
       "      <td>-13.763821</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>33.99</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14.082278</td>\n",
       "      <td>-13.682278</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>33.97</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>6</td>\n",
       "      <td>7.232220</td>\n",
       "      <td>-15.232220</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>56.09</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>6</td>\n",
       "      <td>7.781863</td>\n",
       "      <td>-15.981863</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>53.54</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>6</td>\n",
       "      <td>7.696912</td>\n",
       "      <td>-15.996912</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>53.89</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>6</td>\n",
       "      <td>8.128435</td>\n",
       "      <td>-16.528435</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>51.96</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>6</td>\n",
       "      <td>8.128435</td>\n",
       "      <td>-16.528435</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>51.96</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day       T-Td         Td  Hour  Minute  DHI  DNI   WS     RH    T  week  \\\n",
       "0      0  13.876055 -13.876055     0       0    0    0  2.7  34.42  0.0     0   \n",
       "1      0  13.976610 -13.876610     0      30    0    0  2.7  34.17  0.1     0   \n",
       "2      0  13.966234 -13.766234     1       0    0    0  2.7  34.23  0.2     0   \n",
       "3      0  14.063821 -13.763821     1      30    0    0  2.7  33.99  0.3     0   \n",
       "4      0  14.082278 -13.682278     2       0    0    0  2.8  33.97  0.4     0   \n",
       "..   ...        ...        ...   ...     ...  ...  ...  ...    ...  ...   ...   \n",
       "331    6   7.232220 -15.232220    21      30    0    0  3.6  56.09 -8.0     0   \n",
       "332    6   7.781863 -15.981863    22       0    0    0  3.4  53.54 -8.2     0   \n",
       "333    6   7.696912 -15.996912    22      30    0    0  3.4  53.89 -8.3     0   \n",
       "334    6   8.128435 -16.528435    23       0    0    0  3.4  51.96 -8.4     0   \n",
       "335    6   8.128435 -16.528435    23      30    0    0  3.4  51.96 -8.4     0   \n",
       "\n",
       "     sum_energy  theta  GHI  \n",
       "0             0      0  0.0  \n",
       "1             0      0  0.0  \n",
       "2             0      0  0.0  \n",
       "3             0      0  0.0  \n",
       "4             0      0  0.0  \n",
       "..          ...    ...  ...  \n",
       "331           0      0  0.0  \n",
       "332           0      0  0.0  \n",
       "333           0      0  0.0  \n",
       "334           0      0  0.0  \n",
       "335           0      0  0.0  \n",
       "\n",
       "[336 rows x 14 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for submit\n",
    "\n",
    "i=0\n",
    "path = '../00_data/test/' + str(i) + '.csv'\n",
    "df = preprocess(path, 0, add_var = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = pd.DataFrame([])\n",
    "for i in range(len(quantile)):\n",
    "    regressor = models1[i]\n",
    "    pred = pd.Series(model.predict(df).round(2))\n",
    "    pred_list = pd.concat([pred_list, pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result < 0]=0\n",
    "    hour = X_test.Hour.reset_index(drop=True).copy()\n",
    "    result = pd.concat([result, hour], axis=1)\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        if (result['Hour'].iloc[i] < 6) | (result['Hour'].iloc[i] > 20):\n",
    "            result.iloc[i, :] == 0\n",
    "\n",
    "    result = result.drop('Hour', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global quantile\n",
    "\n",
    "final_result = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,81):\n",
    "    path = '../00_data/test/' + str(i) + '.csv'\n",
    "    df2 = preprocess(path, add_var = True)\n",
    "    X, y = data_split3(df2, train = False)\n",
    "    X1 = X.copy()\n",
    "    X1['Minute'] = X1['Minute'].astype('str')\n",
    "    X1['Minute'] = X1['Minute'].replace('0','00')\n",
    "    dtest = xgb.DMatrix(data=X, label=y)\n",
    "    \n",
    "    result = pd.DataFrame([])\n",
    "    result['y_true'] = y.values\n",
    "    result['id'] = 0\n",
    "    result['day'] = 0\n",
    "    result['hour'] = 0\n",
    "    \n",
    "    for j,k in enumerate([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "        quantile = k\n",
    "        loss = 0\n",
    "        file_name = 'model_{}.pkl'.format(k) \n",
    "        model = joblib.load(file_name) \n",
    "        \n",
    "        for h in range(len(X)):\n",
    "            result['id'].loc[h] = '{}.csv_Day{}_{}h{}m'.format(i, X1['Day'].loc[h]+4,X1['Hour'].loc[h], X1['Minute'].loc[h])\n",
    "            result['day'].loc[h] = X['Day'].loc[h]+4\n",
    "            result['hour'].loc[h] = X['Hour'].loc[h]\n",
    "    \n",
    "        result['q_{}'.format(k)] = model.predict(dtest) * 1.3\n",
    "        \n",
    "        for h in range(len(X)):\n",
    "            if (result['hour'].iloc[h] < 6) | (result['hour'].iloc[h] > 20):\n",
    "                result['q_{}'.format(k)].iloc[h] = 0\n",
    "            if result['q_{}'.format(k)].iloc[h] < 0:\n",
    "                result['q_{}'.format(k)].iloc[h] = 0\n",
    "                \n",
    "        loss += compute_quantile_loss(result['y_true'], result.iloc[:,j+4], quantile = k)\n",
    "        #print(result.columns)\n",
    "    print('=================================================')\n",
    "    final_result = pd.concat([final_result, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantile별 model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n",
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33576, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 18.201061\n",
      "[20]\tvalid_0's l2: 512.324\n",
      "[40]\tvalid_0's l2: 405.399\n",
      "[60]\tvalid_0's l2: 331.41\n",
      "[80]\tvalid_0's l2: 277.715\n",
      "[100]\tvalid_0's l2: 241.972\n",
      "[120]\tvalid_0's l2: 218.474\n",
      "[140]\tvalid_0's l2: 201.875\n",
      "[160]\tvalid_0's l2: 189.063\n",
      "[180]\tvalid_0's l2: 181.554\n",
      "[200]\tvalid_0's l2: 175.346\n",
      "[220]\tvalid_0's l2: 171.117\n",
      "[240]\tvalid_0's l2: 167.43\n",
      "[260]\tvalid_0's l2: 164.684\n",
      "[280]\tvalid_0's l2: 163.263\n",
      "[300]\tvalid_0's l2: 162.039\n",
      "[320]\tvalid_0's l2: 161.27\n",
      "[340]\tvalid_0's l2: 161.001\n",
      "[360]\tvalid_0's l2: 160.837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[380]\tvalid_0's l2: 160.717\n",
      "[400]\tvalid_0's l2: 160.456\n",
      "[420]\tvalid_0's l2: 160.299\n",
      "[440]\tvalid_0's l2: 161.393\n",
      "[460]\tvalid_0's l2: 161.25\n",
      "[480]\tvalid_0's l2: 161.533\n",
      "[500]\tvalid_0's l2: 161.898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l2: 161.88\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\tvalid_0's l2: 162.262\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\tvalid_0's l2: 162.524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l2: 162.429\n",
      "[600]\tvalid_0's l2: 162.613\n"
     ]
    }
   ],
   "source": [
    "quantile = np.arange(0.1, 1, 0.1)\n",
    "model_list = {}\n",
    "for i in range(len(quantile)):\n",
    "    model_list[i] = lgb.train(params, train_ds, 600, test_ds, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
