{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import sklearn\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn import ensemble\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import scipy as sp\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "train_dir = os.path.join(base_dir, 'train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(train_dir)\n",
    "base_df.head()\n",
    "\n",
    "base_df['Time'] = base_df['Hour']*60 + base_df['Minute']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_dataset(inputdata):\n",
    "    # Shift\n",
    "    shift_df = inputdata.copy()\n",
    "\n",
    "    shift_df['TARGET1'] = shift_df['TARGET'].shift(-48).fillna(method='ffill')\n",
    "    shift_df['TARGET2'] = shift_df['TARGET'].shift(-96).fillna(method='ffill')\n",
    "\n",
    "    shift_df_result = shift_df.iloc[:-96]\n",
    "    \n",
    "    return shift_df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ghi(inputdata):\n",
    "    \n",
    "    df = inputdata.copy()\n",
    "    \n",
    "    # 전체 도달 에너지량 \n",
    "    df['sum_energy'] = df['DHI'] + df['DNI']\n",
    "\n",
    "    # 태양고도\n",
    "    df['theta'] = 0\n",
    "    condition_list = [\n",
    "        (df['Hour'] == 6) | (df['Hour'] == 19),\n",
    "        (df['Hour'] == 7) | (df['Hour'] == 18),\n",
    "        (df['Hour'] == 8) | (df['Hour'] == 17),\n",
    "        (df['Hour'] == 9) | (df['Hour'] == 16),\n",
    "        (df['Hour'] == 10) | (df['Hour'] == 15),\n",
    "        (df['Hour'] == 11) | (df['Hour'] == 14),\n",
    "        (df['Hour'] == 12) | (df['Hour'] == 13)\n",
    "    ]\n",
    "\n",
    "    choice_list = [0,10,20,30,40,50,60]\n",
    "\n",
    "    df['theta'] = np.select(condition_list, choice_list)\n",
    "\n",
    "    # GHI\n",
    "    df['GHI'] = df['DNI'] * np.cos(df['theta']) + df['DHI']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Td, T-Td\n",
    "def make_dp(inputdata):\n",
    "    \n",
    "    tempdf = inputdata\n",
    "    \n",
    "    b = 17.62\n",
    "    c = 243.12\n",
    "    term1 = b*tempdf['T']/(c + tempdf['T'])\n",
    "    term2 = np.log(tempdf['RH']/100)\n",
    "    gamma = term1 + term2\n",
    "    dp = (c*gamma)/(b-gamma)\n",
    "\n",
    "    tempdf['DP'] = dp\n",
    "    \n",
    "    return tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataset(inputdata, dataset_type=None):\n",
    "    \n",
    "    temp_df = inputdata.copy()\n",
    "    \n",
    "    if dataset_type:\n",
    "        temp_df = shift_dataset(temp_df)\n",
    "    \n",
    "    temp_df = make_ghi(temp_df)\n",
    "    temp_df = make_dp(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = set_dataset(base_df, 'train')\n",
    "logger.info(f\"Setting Basic Dataset Completed --- shape:{var_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * make arbitrary testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_vars = ['Time', 'DHI', 'DNI', 'WS', 'RH', 'T', 'DP', 'GHI', 'TARGET']\n",
    "\n",
    "# load testset (81 csv files)\n",
    "base_dir = os.getcwd()\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "df_test = []\n",
    "for i in range(81):\n",
    "    \n",
    "    file_path = os.path.join(test_dir, str(i)+'.csv')\n",
    "    temp = pd.read_csv(file_path)\n",
    "    \n",
    "    temp['Time'] = temp['Hour']*60 + temp['Minute']\n",
    "    \n",
    "    fin_testset = set_dataset(temp)\n",
    "    fin_testset = fin_testset.loc[fin_testset.Day == 6, :][needed_vars]\n",
    "    \n",
    "    df_test.append(fin_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arbi_test(input_test, input_train):\n",
    "    \n",
    "    org_trainset_shape = input_train.shape\n",
    "    \n",
    "    # similarity based calling\n",
    "    fin_testindex = []\n",
    "    for i in range(81):\n",
    "        temp_testdf = input_test[i]\n",
    "        dsc1 = temp_testdf.loc[temp_testdf.TARGET > 0.0].describe()['DHI']\n",
    "        dsc2 = temp_testdf.loc[temp_testdf.TARGET > 0.0].describe()['T']\n",
    "\n",
    "        dsc1_range = (dsc1[6]*0.8, dsc1[6]*1.2)\n",
    "        dsc2_range = (dsc2[6]*0.8, dsc2[6]*1.2)\n",
    "\n",
    "        candids = input_train.loc[(input_train['DHI'] >= dsc1_range[0]) & (input_train['DHI'] <= dsc1_range[1]) &\n",
    "                                  (input_train['T'] >= dsc2_range[0]) & (input_train['T'] <= dsc2_range[1]), ]\n",
    "\n",
    "        if len(candids) < 400:\n",
    "            fin_testindex.extend(random.sample(list(input_train.index), 40))\n",
    "        else:\n",
    "            fin_testindex.extend(random.sample(list(candids.index), 40))\n",
    "    \n",
    "    logger.info(f\"Called similar train data\")\n",
    "    \n",
    "    # data with zeros\n",
    "    zeroset = random.sample(list(input_train.loc[input_train['TARGET'] == 0, ].index), 2000)\n",
    "    fin_testindex.extend(zeroset)\n",
    "    \n",
    "    logger.info(f\"Called train data with zero target value\")\n",
    "    \n",
    "    # drop duplicates\n",
    "    fin_testindex = list(set(fin_testindex))\n",
    "    \n",
    "    testset = input_train.loc[fin_testindex, ]\n",
    "    input_train = input_train.drop(index=fin_testindex)\n",
    "    \n",
    "    logger.info(f\"Origin Trainset: {org_trainset_shape} | Trainset after sampling: {input_train.shape} | Testset: {testset.shape}\")\n",
    "    \n",
    "    return testset, input_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset, trainset = make_arbi_test(df_test, var_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_vars = ['Time', 'DHI', 'DNI', 'WS', 'RH', 'T', 'DP', 'GHI', 'TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = testset[needed_vars]\n",
    "test_Y = testset[['TARGET1', 'TARGET2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vars = trainset[needed_vars]\n",
    "df_label = trainset[['TARGET1', 'TARGET2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(test_size = 0.2, *datasets):\n",
    "    \n",
    "    df_vars = datasets[0]\n",
    "    df_label = datasets[1]\n",
    "    \n",
    "    train_x, val_x, train_y, val_y = tts(df_vars, df_label, test_size = test_size, random_state = 2021)\n",
    "    \n",
    "    train_y_t1 = train_y.iloc[:, 0:1]\n",
    "    train_y_t2 = train_y.iloc[:, 1:2]\n",
    "    \n",
    "    val_y_t1 = val_y.iloc[:, 0:1]\n",
    "    val_y_t2 = val_y.iloc[:, 1:2]\n",
    "    \n",
    "    return train_x, val_x, train_y_t1, train_y_t2, val_y_t1, val_y_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y_t1, train_y_t2, val_y_t1, val_y_t2 = split_df(0.2, df_vars, df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model and the predictions in (a) - (b)\n",
    "def lgbm_model(q, X_train, Y_train, X_valid, Y_valid):\n",
    "    \n",
    "    # (a) Modeling\n",
    "    model = LGBMRegressor(objective='quantile', alpha=q, max_depth=128, boosting='gbdt',\n",
    "                         n_estimators=750, num_leaves=152, bagging_fraction=0.5, learning_rate=0.02)                   \n",
    "    \n",
    "    model.fit(X_train, Y_train, eval_metric = ['quantile'], \n",
    "          eval_set=[(X_valid, Y_valid)], early_stopping_rounds=512, verbose=500)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(X_train, Y_train, X_valid, Y_valid):\n",
    "\n",
    "    LGBM_models=[]\n",
    "    quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    \n",
    "    for q in quantiles:\n",
    "        print(f\"Qunatile: {q}\")\n",
    "        model = lgbm_model(q, X_train, Y_train, X_valid, Y_valid)\n",
    "        LGBM_models.append(model)\n",
    "    \n",
    "    return LGBM_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_1 = train_lgbm(train_x, train_y_t1, val_x, val_y_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_2 = train_lgbm(train_x, train_y_t2, val_x, val_y_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(gt, pred, tau):\n",
    "    error = gt - pred\n",
    "    loss = np.mean(np.maximum(tau * error, (tau - 1) * error))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pred(model_lists, input_gt, input_testset, quantiles):\n",
    "    \n",
    "    model = model_lists\n",
    "    input_testset = input_testset\n",
    "    gt = input_gt.values.reshape(-1)\n",
    "    \n",
    "    preds = [model_q.predict(input_testset) for i, model_q in enumerate(model)]\n",
    "    losses = [quantile_loss(gt, pred, quantiles[i]) for i, pred in enumerate(preds)]\n",
    "    \n",
    "    fin_loss = sum(losses)/len(losses)\n",
    "    \n",
    "    logger.info(f\"Test on testset completed --- loss: {fin_loss:.4f}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "test_pred(models_1, val_y_t1, val_x, quantiles)\n",
    "test_pred(models_2, val_y_t2, val_x, quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred(models_1, test_Y.iloc[:, 0:1], test_X, quantiles)\n",
    "test_pred(models_2, test_Y.iloc[:, 1:2], test_X, quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(base_dir, 'test')\n",
    "lists = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = []\n",
    "\n",
    "for i in range(81):\n",
    "    \n",
    "    file_path = os.path.join(test_dir, str(i)+'.csv')\n",
    "    temp = pd.read_csv(file_path)\n",
    "    \n",
    "    temp['Time'] = temp['Hour']*60 + temp['Minute']\n",
    "    \n",
    "    fin_testset = set_dataset(temp)\n",
    "    fin_testset = fin_testset.loc[fin_testset.Day == 6, :][needed_vars]\n",
    "    \n",
    "    df_test.append(fin_testset)\n",
    "\n",
    "X_test = pd.concat(df_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred1 = pd.DataFrame(np.array([models_1[i].predict(X_test) for i in range(9)]).transpose()).round(4)\n",
    "test_pred2 = pd.DataFrame(np.array([models_2[i].predict(X_test) for i in range(9)]).transpose()).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = test_pred1.values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = test_pred2.values\n",
    "submission.iloc[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zeros(inputdata, target_hours):\n",
    "    \n",
    "    def find_zero(x): return x['id'].split('.')[1].split('_')[-1].split('h')[0] in target_hours\n",
    "    \n",
    "    to_fill = inputdata.loc[inputdata.apply(find_zero, axis = 1), 'q_0.1':]\n",
    "    zeros_array = np.zeros(to_fill.shape)\n",
    "    \n",
    "    inputdata.loc[inputdata.apply(find_zero, axis = 1), 'q_0.1':] = zeros_array\n",
    "    logger.info(f\"Filled target spaces with zeros, final dataset set!\")\n",
    "    \n",
    "    return inputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_hours = ['0', '1', '2', '3', '4', '20', '21', '22', '23']\n",
    "\n",
    "fin_result = fill_zeros(submission, target_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './submission/submission_0118_v0.csv'\n",
    "if os.path.exists(save_path):\n",
    "    raise Exception(\"Same submission file already exists!\")\n",
    "else:\n",
    "    fin_result.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "dacon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
